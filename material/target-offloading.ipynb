{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f7b5889-68f8-4ecd-a8a5-09634b0f2637",
   "metadata": {},
   "source": [
    "# Target Offloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3883eb82-3cef-45ad-82ee-87d317977c78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78054ba2-81f3-4563-9cbb-85a7cc93e658",
   "metadata": {},
   "source": [
    "We start by reviewing a short presentation.\n",
    "Execute the cell below to display it or download and open it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de16572a-8c33-417f-912a-3772ef03b390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div align=\"center\"><iframe src=\"slides/Introduction-to-GPU-Computing.pdf\" width=800 height=500 frameborder=0></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ef696",
   "metadata": {},
   "source": [
    "\n",
    "In contrast to other GPU programming approaches, OpenMP follows a slightly different naming convention ([OpenMP 5.1 - 1.2.1](https://www.openmp.org/spec-html/5.1/openmpsu1.html)).\n",
    "* A *device* is 'an implementation-defined logical execution engine'.\n",
    "* The *host*, or *initial device*, is the device on which the OpenMP program begins execution.\n",
    "* The *target* is a device onto which code and data may be offloaded from the host device. In many cases it is a GPU, but it doesn't have to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4878951-cb55-4899-9bab-d3b3266d1ec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext ice.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29636356-aefb-4982-a045-76d1eb774de6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38109048-3b98-4887-ae91-3ab5e28977b3",
   "metadata": {},
   "source": [
    "The `target` construct transfers execution to the device (target) ([OpenMP 5.1 - 2.14.5](https://www.openmp.org/spec-html/5.1/openmpsu68.html)).\n",
    "\\\n",
    "Everything within the target block is executed on the target.\n",
    "Only a sub-set of features is available, e.g. no `std::cout`. If you are familiar with other GPU programming approaches -- similar restrictions apply with OpenMP as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4531ff-dbf8-4e4a-be1c-638d6c528a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/hello-world.cpp\n",
    "\n",
    "std::cout << \"Hello from the CPU\" << std::endl;\n",
    "\n",
    "#pragma omp target\n",
    "{           ☝\n",
    "    printf(\"Hello from the GPU\\n\");\n",
    "} //# implicit synchronization with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc8b6ad-3e64-4a0d-9c03-538889757e36",
   "metadata": {},
   "source": [
    "### Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b167b09-bf5a-4baa-990f-2bdf0892a2a0",
   "metadata": {},
   "source": [
    "You might have noticed that we used a different magic this time -- `cpp_omp_target`.\n",
    "\\\n",
    "This switches to a different compiler, `nvc++`, and adds a different set of flags.\n",
    "As before, using the `-v` switch displays more detailed information.\n",
    "\\\n",
    "Adding the optional `-Minfo=mp` compiler flag triggers the compiler to emit information about how the application is mapped to the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f79fa-28ce-491f-a1b0-a90f1707dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/hello-world.cpp -f Minfo=mp\n",
    "\n",
    "std::cout << \"Hello from the CPU\" << std::endl;\n",
    "\n",
    "#pragma omp target\n",
    "{\n",
    "    printf(\"Hello from the GPU\\n\");\n",
    "} //# implicit synchronization with the target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb2ba27-eb93-45b6-b541-a341dd3655fd",
   "metadata": {},
   "source": [
    "### Checking for Host Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f27545-9679-4219-b19b-797d8175a80a",
   "metadata": {},
   "source": [
    "In some cases it might be necessary to programmatically check whether execution is currently on the host or on the device, e.g. when using multiple nested functions.\n",
    "`omp_is_initial_device` can be used to perform that check ([OpenMP 5.1 - 3.7.6](https://www.openmp.org/spec-html/5.1/openmpsu166.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82106874-cbf2-4b2e-a4b1-0fe2e195d857",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/initial-device.cpp\n",
    "\n",
    "std::cout << omp_is_initial_device() << std::endl;\n",
    "             ☝\n",
    "\n",
    "#pragma omp target\n",
    "{\n",
    "    printf(\"%d\\n\", omp_is_initial_device());\n",
    "                   ☝\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd172a9-395c-428c-84a5-8941f3054fa4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Parallel Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23efce-faf0-4f1b-9917-9895a6b859d5",
   "metadata": {},
   "source": [
    "So far, everything in our `target` region has been executed serially since the target construct doesn't generate parallelism.\n",
    "\\\n",
    "In the following steps, we will add hierarchical parallelism (to match the GPU architecture discussed before), and workload sharing.\n",
    "\\\n",
    "We will use the the following example as baseline.\n",
    "In it, the loop is executed on the device, but only with a single thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438b813e-81f9-4b1c-8626-f8b5964169c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-serial.cpp\n",
    "\n",
    "#pragma omp target\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"%d\\n\", i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719ade41-05c9-4ff3-b544-bf85d07234b6",
   "metadata": {},
   "source": [
    "### Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f35a80-951c-453a-8013-40287a684e5c",
   "metadata": {},
   "source": [
    "`teams` construct generates a *league of teams* ([OpenMP 5.1 - 2.7](https://www.openmp.org/spec-html/5.1/openmpse15.html)).\n",
    "\\\n",
    "A team is comparable but not necessarily identical to a CUDA thread block.\n",
    "Each team initially has only one thread and each team executes the same code.\n",
    "The number of teams can be *limited* with `num_teams` -- this sets an upper bound, not the exact number.\n",
    "\n",
    "The id of the current team can be querried with `omp_get_team_num` ([OpenMP 5.1 - 3.4.2](https://www.openmp.org/spec-html/5.1/openmpsu152.html)).\n",
    "\\\n",
    "`omp_get_thread_num` returns the current thread id *within the current team*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b6ee17-a60a-4777-868e-d5f631b5238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-teams.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "            ☝   ☝\n",
    "    printf(\"Team %d, thread %d\\n\", omp_get_team_num(), omp_get_thread_num());\n",
    "                                   ☝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c09de1-a2bc-455b-98c6-ef2524d65567",
   "metadata": {},
   "source": [
    "### Parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51823090-7ff3-41d6-9384-355e879d88b1",
   "metadata": {},
   "source": [
    "`parallel` generates a parallel region with multiple threads per team.\n",
    "The number of threads per team can be limited with `thread_limit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad51114-b003-4d2a-9282-c8a899b1cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/thread-limit.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams parallel num_teams(2) thread_limit(2)\n",
    "                  ☝                    ☝\n",
    "    printf(\"Team %d, thread %d\\n\", omp_get_team_num(), omp_get_thread_num());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827e6423-82a2-438e-8be4-997d0b6f7f03",
   "metadata": {},
   "source": [
    "### Distribute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf0db01-64fb-437c-8d32-021c8a278e3a",
   "metadata": {},
   "source": [
    "For loops, worksharing constructs are required additionally.\n",
    "\n",
    "`distribute` distributes the iteration space across teams ([OpenMP 5.1 - 2.11.6](https://www.openmp.org/spec-html/5.1/openmpsu50.html)).\n",
    "\\\n",
    "Schedules can be specified using `dist_schedule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f8d96-902e-45b3-a055-57c83ff0d704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-distribute.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "#pragma omp distribute\n",
    "            ☝\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64101ec-34fa-436e-93b9-16151c70455b",
   "metadata": {},
   "source": [
    "### For"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bb712c-75ce-4935-b6e3-75830a5356e6",
   "metadata": {},
   "source": [
    "`for` distributes the *team's* iteration space over the team's threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5ba23-6e11-4cd4-b69c-0404baa845ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-for.cpp\n",
    "\n",
    "#pragma omp target\n",
    "#pragma omp teams num_teams(2)\n",
    "#pragma omp distribute parallel for\n",
    "                                ☝\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ba7ee-c8f4-43b7-b471-0c01c3bbddfb",
   "metadata": {},
   "source": [
    "### SIMD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c28274-a9a4-404d-b282-4e4f592fd268",
   "metadata": {},
   "source": [
    "Additionally, the `simd` construct is also available.\n",
    "What exactly is mapped how is compiler dependent.\n",
    "For NVIDIA, *usually* teams are mapped to CUDA thread blocks, threads are mapped to CUDA threads and simd is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cd76c3-ca3e-43e1-8dbe-a4d05ef6e811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-simd.cpp\n",
    "\n",
    "#pragma omp target teams distribute parallel for simd\n",
    "                                                 ☝\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4dff40-513a-4df7-93a2-2cdedb8d60f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Collapsing Loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f862608b-e8cc-42b4-94a5-a9ae9607db98",
   "metadata": {},
   "source": [
    "Similar to how loops are handled on CPU, `collapse` can be used to merge multiple loops in a perfect nest.\n",
    "This is especially important on GPUs since massive parallelism is required to fully utilize the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482aa92d-d488-4852-859a-d8fe8bc9095e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/collapse.cpp\n",
    "\n",
    "#pragma omp target teams distribute parallel for simd collapse(2)\n",
    "                                                      ☝\n",
    "for (auto i = 0; i < 2; ++i)\n",
    "    for (auto j = 0; j < 5; ++j)\n",
    "        printf(\"Team %d, thread %d, i = %d\\n\", omp_get_team_num(), omp_get_thread_num(), i * 5 + j);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca1d9f8-90c4-40ff-b922-1019beb84527",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Target Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b605f-4e66-410e-88a9-39dfc4fac46a",
   "metadata": {},
   "source": [
    "Target regions span their own data environment.\n",
    "In addition to the clauses already discussed in the [data environment](data-environment.ipynb) notebook, target data mapping clauses are available.\n",
    "Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872becf-2223-45ef-9870-2f00520549f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/map.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for map(tofrom: vec[0:10])\n",
    "                                                 ☝\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f351fa37-15aa-41a4-9d5d-b142cb87e0b5",
   "metadata": {},
   "source": [
    "Here, the contents of `vec` are copied to the target when entering the target region and copied back to the host when leaving it.\n",
    "Available map types in the `map` clause are\n",
    "* `to` which copies data from host to target,\n",
    "* `from` which copies data from target to host,\n",
    "* `tofrom` which combines the behavior of to and from, and\n",
    "* `alloc` which allocates data on the target but does not initialize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6d3201-f928-411c-ac95-7567326418d3",
   "metadata": {},
   "source": [
    "### Implicit Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5865965-ee66-480b-9389-21052d5aec36",
   "metadata": {},
   "source": [
    "Target data environments implement the following implicit behavior if not specified otherwise:\n",
    "* Scalar variables are `firstprivate`\n",
    "    * They are copied to the device and each thread has its own version\n",
    "    * Changes are neither synchronized between threads nor copied back to the host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828c7b51-169e-4917-bab8-bfa323cbbb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/implicit-data.cpp\n",
    "\n",
    "int a = 10;\n",
    "   ☝\n",
    "static int b = 20;\n",
    "          ☝\n",
    "\n",
    "#pragma omp target teams parallel\n",
    "if (0 == omp_get_team_num() && 0 == omp_get_thread_num()) {\n",
    "    printf(\"a = %d, b = %d\\n\", a, b);\n",
    "    a *= 10;\n",
    "    b *= 10;\n",
    "}\n",
    "\n",
    "printf(\"a = %d, b = %d\\n\", a, b);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158b8ad7-4847-47a0-9b78-f0cb31b905d3",
   "metadata": {},
   "source": [
    "* Statically allocated arrays are treated as `map(tofrom)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3bdd5-1ffd-4cf9-935e-0e2677230b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/static-array.cpp\n",
    "\n",
    "int vec[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n",
    "    ☝\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (const auto& val : vec)\n",
    "    std::cout << val << \" \";\n",
    "std::cout << std::endl;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebabcb2c-e2c3-4c7f-863f-b9bc5d9a62c1",
   "metadata": {},
   "source": [
    "* Dynamically allocated arrays need to be mapped explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e6475-826c-4ada-ada3-c1a47d76e249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/missing-map.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "    ☝\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "//# due to the missing map clause, this example will not work\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4746af-bd7e-4979-89b2-838b9f0e73ab",
   "metadata": {},
   "source": [
    "### Target Data Region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ead81-af78-4582-b59e-c8ed35400846",
   "metadata": {},
   "source": [
    "Mapping data for each target region individually can generate some drawbacks (code bloating, performance issues).\n",
    "OpenMP offers `target data` constructs as an alternative ([OpenMP 5.1 - 2.14.2](https://www.openmp.org/spec-html/5.1/openmpsu65.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857ce2c-6ece-4f10-8965-c5bc1438cede",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/target-data.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target data map(tofrom: vec[0:10])\n",
    "{                 ☝\n",
    "    #pragma omp target teams distribute parallel for\n",
    "    for (auto i = 0; i < 10; ++i)\n",
    "        vec[i] *= 2;\n",
    "\n",
    "    #pragma omp target teams distribute parallel for\n",
    "    for (auto i = 0; i < 10; ++i)\n",
    "        vec[i] *= 2;\n",
    "}\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fc266-5dbf-4e78-b4a3-d7e1cf444d19",
   "metadata": {},
   "source": [
    "If the software architecture requires a more unstructured approach `target enter data` ([OpenMP 5.1 - 2.14.3](https://www.openmp.org/spec-html/5.1/openmpsu66.html)) and `target exit data` ([OpenMP 5.1 - 2.14.4](https://www.openmp.org/spec-html/5.1/openmpsu67.html)) are available.\n",
    "These can be helpful when performing the mapping in separate functions, e.g. in the constructor and destructor of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e288218-1c33-40af-bbf5-31a0afd7e622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/enter-data.cpp\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target enter data map(to: vec[0:10])\n",
    "                  ☝\n",
    "\n",
    "#pragma omp target teams distribute parallel for\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "#pragma omp target exit data map(from: vec[0:10])\n",
    "                  ☝\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915ff4a-a5e4-4ebd-934e-b42e7b60427c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## An Aside on Managed Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4344b0e7-3624-4e67-9c18-5ea023e50476",
   "metadata": {},
   "source": [
    "On newer architecture, managed memory or unified memory is available as an alternative (see, e.g., this [blog post](https://developer.nvidia.com/blog/unified-memory-cuda-beginners/)).\n",
    "When used, allocations are done as managed memory and all transfers between host and target are done implicitly.\n",
    "\\\n",
    "In OpenMP it is activated by adding the compiler flag `-gpu=managed` and by specifying `#pragma omp requires unified_shared_memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b828577-960b-4da3-aa28-e6d7db28b86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/managed-mem.cpp -v -f gpu=managed\n",
    "                                                   ☝\n",
    "\n",
    "#pragma omp requires unified_shared_memory\n",
    "           ☝\n",
    "\n",
    "int *vec = new int[10];\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] = i;\n",
    "\n",
    "#pragma omp target teams distribute parallel for // no map clauses\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    vec[i] *= 2;\n",
    "\n",
    "for (auto i = 0; i < 10; ++i)\n",
    "    std::cout << vec[i] << \" \";\n",
    "std::cout << std::endl;\n",
    "\n",
    "free(vec);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbea68-85c4-4257-a2a6-b327395e7f33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Reductions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a664e7-2b5c-4867-a8b3-82cc010bbdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%cpp_omp_target -o code/target/reduction.cpp\n",
    "\n",
    "auto sum = 0;\n",
    "\n",
    "#pragma omp target teams distribute parallel for reduction( + : sum )\n",
    "                                                 ☝\n",
    "for (auto i = 0; i < 100; ++i)\n",
    "    sum += i;\n",
    "\n",
    "std::cout << \"Sum is \" << sum << std::endl;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
